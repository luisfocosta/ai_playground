{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luisfocosta/ai_playground/blob/main/L3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d94fb77-0e21-4a69-b0a5-22d4043896ce",
      "metadata": {
        "id": "7d94fb77-0e21-4a69-b0a5-22d4043896ce"
      },
      "source": [
        "# Lab 3: Building Agents with memory"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c2a96f8-1bc3-4997-8768-987c95639696",
      "metadata": {
        "id": "4c2a96f8-1bc3-4997-8768-987c95639696"
      },
      "source": [
        "## Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3df2c8db-f093-4baa-aaa1-2f700267513c",
      "metadata": {
        "id": "3df2c8db-f093-4baa-aaa1-2f700267513c"
      },
      "source": [
        "<div style=\"background-color:#fff6ff; padding:13px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\">\n",
        "<p> ðŸ’» &nbsp; <b>Access <code>requirements.txt</code> and <code>helper.py</code> files:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Open\"</em>.\n",
        "\n",
        "<p> â¬‡ &nbsp; <b>Download Notebooks:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Download as\"</em> and select <em>\"Notebook (.ipynb)\"</em>.</p>\n",
        "\n",
        "<p> ðŸ“’ &nbsp; For more help, please see the <em>\"Appendix â€“ Tips, Help, and Download\"</em> Lesson.</p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d27a53c6-cac9-410c-868b-bf4e4fcd59e7",
      "metadata": {
        "id": "d27a53c6-cac9-410c-868b-bf4e4fcd59e7"
      },
      "source": [
        "<p style=\"background-color:#f7fff8; padding:15px; border-width:3px; border-color:#e0f0e0; border-style:solid; border-radius:6px\"> ðŸš¨\n",
        "&nbsp; <b>Different Run Results:</b> The output generated by AI models can vary with each execution due to their dynamic, probabilistic nature. Your results may differ from those shown in the video.</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49e0d506-81de-4257-8f1e-1ccc3af54962",
      "metadata": {
        "id": "49e0d506-81de-4257-8f1e-1ccc3af54962"
      },
      "source": [
        "Letta agents persist information over time and restarts by saving data to a database. These lessons do not require past information. To enable a clean restart, the database is cleared before starting the lesson."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb06a83c-2621-4382-9707-df4fcfbe421d",
      "metadata": {
        "height": 30,
        "id": "fb06a83c-2621-4382-9707-df4fcfbe421d"
      },
      "outputs": [],
      "source": [
        "!rm  -f ~/.letta/sqlite.db"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0edbebca-7bf9-4eba-b3cb-3d5abf8bcecc",
      "metadata": {
        "id": "0edbebca-7bf9-4eba-b3cb-3d5abf8bcecc"
      },
      "source": [
        "## Section 0: Setup a client"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.getcwd())\n",
        "for filename in os.listdir():\n",
        "    print(filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZm0yE7IW7B2",
        "outputId": "2bd1b770-a20e-4ce8-ef32-507705a0005b"
      },
      "id": "YZm0yE7IW7B2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            ".config\n",
            "sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d585ab9c-3ccc-4d26-980f-68e494e53336",
      "metadata": {
        "height": 30,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "d585ab9c-3ccc-4d26-980f-68e494e53336",
        "outputId": "6d59976e-4a53-4dd1-94ba-2f06d3a203d9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'nb_print' from 'helper' (unknown location)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-9e6b0c83d2ba>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mhelper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnb_print\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'nb_print' from 'helper' (unknown location)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "from helper import nb_print"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "137aa217-24bb-4372-b21c-37f21a945c9d",
      "metadata": {
        "height": 64,
        "id": "137aa217-24bb-4372-b21c-37f21a945c9d",
        "outputId": "df70c060-a186-40f2-856f-05d96bec9859"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved Config:  /home/jovyan/.letta/config\n",
            "ðŸ“– Letta configuration file updated!\n",
            "ðŸ§  model\t-> gpt-4\n",
            "ðŸ–¥ï¸  endpoint\t-> http://jupyter-api-proxy.internal.dlai/rev-proxy/letta\n",
            "Saved Config:  /home/jovyan/.letta/config\n",
            "Saved Config:  /home/jovyan/.letta/config\n"
          ]
        }
      ],
      "source": [
        "from letta import create_client\n",
        "\n",
        "client = create_client()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5e108e4-bcf9-4be1-b2c0-66539cbe9ec3",
      "metadata": {
        "height": 79,
        "id": "c5e108e4-bcf9-4be1-b2c0-66539cbe9ec3"
      },
      "outputs": [],
      "source": [
        "from letta.schemas.llm_config import LLMConfig\n",
        "\n",
        "client.set_default_llm_config(LLMConfig.default_config(\"gpt-4o-mini\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29744677-0b25-4a22-85f9-b7ca1635477c",
      "metadata": {
        "id": "29744677-0b25-4a22-85f9-b7ca1635477c"
      },
      "source": [
        "## Section 1: Creating a simple agent with memory"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37703a17-7bfb-48b8-b321-a2debcf0341f",
      "metadata": {
        "id": "37703a17-7bfb-48b8-b321-a2debcf0341f"
      },
      "source": [
        "### Creating an agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a0e6729-0f02-497f-8f85-688ed4f65f68",
      "metadata": {
        "height": 30,
        "id": "7a0e6729-0f02-497f-8f85-688ed4f65f68"
      },
      "outputs": [],
      "source": [
        "agent_name = \"simple_agent\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f52b2313-1c8f-4119-aeaa-451198f161a9",
      "metadata": {
        "height": 79,
        "id": "f52b2313-1c8f-4119-aeaa-451198f161a9"
      },
      "outputs": [],
      "source": [
        "# this is not in the video. It deletes the agent if you are running this a 2nd time.\n",
        "if client.get_agent_id(agent_name):\n",
        "    client.delete_agent(client.get_agent_id(agent_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16bbb19b-2fa2-4cac-8803-5cb179c36d47",
      "metadata": {
        "height": 181,
        "id": "16bbb19b-2fa2-4cac-8803-5cb179c36d47"
      },
      "outputs": [],
      "source": [
        "from letta.schemas.memory import ChatMemory\n",
        "\n",
        "agent_state = client.create_agent(\n",
        "    name=agent_name,\n",
        "    memory=ChatMemory(\n",
        "        human=\"My name is Sarah\",\n",
        "        persona=\"You are a helpful assistant that loves emojis\"\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ed0f467-c545-4b26-8a10-2cb009240b5a",
      "metadata": {
        "height": 98,
        "id": "1ed0f467-c545-4b26-8a10-2cb009240b5a",
        "outputId": "5c6f0ede-94d5-4e65-ff2d-c9ffa61b45ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Letta.letta.server.server - ERROR - Error in server._step: 500 Server Error: Internal Server Error for url: http://jupyter-api-proxy.internal.dlai/rev-proxy/letta/chat/completions\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/site-packages/letta/server/server.py\", line 323, in _step\n",
            "    step_response = letta_agent.step(\n",
            "                    ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/site-packages/letta/agent.py\", line 897, in step\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.11/site-packages/letta/agent.py\", line 804, in step\n",
            "    response = self._get_ai_reply(\n",
            "               ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/site-packages/letta/agent.py\", line 495, in _get_ai_reply\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.11/site-packages/letta/agent.py\", line 464, in _get_ai_reply\n",
            "    response = create(\n",
            "               ^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/site-packages/letta/llm_api/llm_api_tools.py\", line 197, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/site-packages/letta/llm_api/llm_api_tools.py\", line 329, in create\n",
            "    response = openai_chat_completions_request(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/site-packages/letta/llm_api/openai.py\", line 432, in openai_chat_completions_request\n",
            "    raise http_err\n",
            "  File \"/usr/local/lib/python3.11/site-packages/letta/llm_api/openai.py\", line 422, in openai_chat_completions_request\n",
            "    response.raise_for_status()  # Raises HTTPError for 4XX/5XX status\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/site-packages/requests/models.py\", line 1024, in raise_for_status\n",
            "    raise HTTPError(http_error_msg, response=self)\n",
            "requests.exceptions.HTTPError: 500 Server Error: Internal Server Error for url: http://jupyter-api-proxy.internal.dlai/rev-proxy/letta/chat/completions\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n"
          ]
        },
        {
          "ename": "HTTPError",
          "evalue": "500 Server Error: Internal Server Error for url: http://jupyter-api-proxy.internal.dlai/rev-proxy/letta/chat/completions",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_message\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43magent_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43magent_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhello!\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrole\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/letta/client/client.py:1734\u001b[0m, in \u001b[0;36mLocalClient.send_message\u001b[0;34m(self, message, role, agent_id, agent_name, stream_steps, stream_tokens, include_full_message)\u001b[0m\n\u001b[1;32m   1732\u001b[0m     usage \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mserver\u001b[38;5;241m.\u001b[39msystem_message(user_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_id, agent_id\u001b[38;5;241m=\u001b[39magent_id, message\u001b[38;5;241m=\u001b[39mmessage)\n\u001b[1;32m   1733\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m role \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1734\u001b[0m     usage \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muser_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muser_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43magent_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1736\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRole \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrole\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/letta/server/server.py:541\u001b[0m, in \u001b[0;36mSyncServer.user_message\u001b[0;34m(self, user_id, agent_id, message, timestamp)\u001b[0m\n\u001b[1;32m    533\u001b[0m         message \u001b[38;5;241m=\u001b[39m Message(\n\u001b[1;32m    534\u001b[0m             user_id\u001b[38;5;241m=\u001b[39muser_id,\n\u001b[1;32m    535\u001b[0m             agent_id\u001b[38;5;241m=\u001b[39magent_id,\n\u001b[1;32m    536\u001b[0m             role\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    537\u001b[0m             text\u001b[38;5;241m=\u001b[39mpackaged_user_message,\n\u001b[1;32m    538\u001b[0m         )\n\u001b[1;32m    540\u001b[0m \u001b[38;5;66;03m# Run the agent state forward\u001b[39;00m\n\u001b[0;32m--> 541\u001b[0m usage \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43magent_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_message\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpackaged_user_message\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimestamp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimestamp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m usage\n",
            "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/letta/server/server.py:323\u001b[0m, in \u001b[0;36mSyncServer._step\u001b[0;34m(self, user_id, agent_id, input_message, timestamp)\u001b[0m\n\u001b[1;32m    321\u001b[0m step_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 323\u001b[0m     step_response \u001b[38;5;241m=\u001b[39m \u001b[43mletta_agent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnext_input_message\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfirst_message\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskip_verify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mno_verify\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dicts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_streaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimestamp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimestamp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    332\u001b[0m     step_response\u001b[38;5;241m.\u001b[39mmessages\n\u001b[1;32m    333\u001b[0m     heartbeat_request \u001b[38;5;241m=\u001b[39m step_response\u001b[38;5;241m.\u001b[39mheartbeat_request\n",
            "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/letta/agent.py:897\u001b[0m, in \u001b[0;36mAgent.step\u001b[0;34m(self, user_message, first_message, first_message_retry_limit, skip_verify, return_dicts, recreate_message_timestamp, stream, timestamp, inner_thoughts_in_kwargs, ms)\u001b[0m\n\u001b[1;32m    895\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    896\u001b[0m     printd(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep() failed with an unrecognized exception: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 897\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
            "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/letta/agent.py:804\u001b[0m, in \u001b[0;36mAgent.step\u001b[0;34m(self, user_message, first_message, first_message_retry_limit, skip_verify, return_dicts, recreate_message_timestamp, stream, timestamp, inner_thoughts_in_kwargs, ms)\u001b[0m\n\u001b[1;32m    801\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHit first message retry limit (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfirst_message_retry_limit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    803\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 804\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_ai_reply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    805\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessage_sequence\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_message_sequence\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    806\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    807\u001b[0m \u001b[43m        \u001b[49m\u001b[43minner_thoughts_in_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minner_thoughts_in_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    808\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    810\u001b[0m \u001b[38;5;66;03m# Step 3: check if LLM wanted to call a function\u001b[39;00m\n\u001b[1;32m    811\u001b[0m \u001b[38;5;66;03m# (if yes) Step 4: call the function\u001b[39;00m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;66;03m# (if yes) Step 5: send the info on the function call and function response to LLM\u001b[39;00m\n\u001b[1;32m    813\u001b[0m response_message \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\n",
            "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/letta/agent.py:495\u001b[0m, in \u001b[0;36mAgent._get_ai_reply\u001b[0;34m(self, message_sequence, function_call, first_message, stream, inner_thoughts_in_kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 495\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
            "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/letta/agent.py:464\u001b[0m, in \u001b[0;36mAgent._get_ai_reply\u001b[0;34m(self, message_sequence, function_call, first_message, stream, inner_thoughts_in_kwargs)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get response from LLM API\"\"\"\u001b[39;00m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 464\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# agent_state=self.agent_state,\u001b[39;49;00m\n\u001b[1;32m    466\u001b[0m \u001b[43m        \u001b[49m\u001b[43mllm_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magent_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magent_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muser_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessage_sequence\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunctions_python\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctions_python\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    471\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    472\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# hint\u001b[39;49;00m\n\u001b[1;32m    473\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfirst_message\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfirst_message\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# streaming\u001b[39;49;00m\n\u001b[1;32m    475\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_inferface\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# putting inner thoughts in func args or not\u001b[39;49;00m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43minner_thoughts_in_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minner_thoughts_in_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(response\u001b[38;5;241m.\u001b[39mchoices) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    482\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAPI call didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt return a message: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/letta/llm_api/llm_api_tools.py:197\u001b[0m, in \u001b[0;36mretry_with_exponential_backoff.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mHTTPError \u001b[38;5;28;01mas\u001b[39;00m http_err:\n\u001b[1;32m    200\u001b[0m         \u001b[38;5;66;03m# Retry on specified errors\u001b[39;00m\n\u001b[1;32m    201\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m http_err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;129;01min\u001b[39;00m error_codes:\n\u001b[1;32m    202\u001b[0m             \u001b[38;5;66;03m# Increment retries\u001b[39;00m\n",
            "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/letta/llm_api/llm_api_tools.py:329\u001b[0m, in \u001b[0;36mcreate\u001b[0;34m(llm_config, messages, user_id, functions, functions_python, function_call, first_message, use_tool_naming, stream, stream_inferface, inner_thoughts_in_kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m     stream_inferface\u001b[38;5;241m.\u001b[39mstream_start()\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 329\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai_chat_completions_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_endpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# https://api.openai.com/v1 -> https://api.openai.com/v1/chat/completions\u001b[39;49;00m\n\u001b[1;32m    331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopenai_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchat_completion_request\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    335\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(stream_inferface, AgentChunkStreamingInterface):\n",
            "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/letta/llm_api/openai.py:432\u001b[0m, in \u001b[0;36mopenai_chat_completions_request\u001b[0;34m(url, api_key, chat_completion_request)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mHTTPError \u001b[38;5;28;01mas\u001b[39;00m http_err:\n\u001b[1;32m    430\u001b[0m     \u001b[38;5;66;03m# Handle HTTP errors (e.g., response 4XX, 5XX)\u001b[39;00m\n\u001b[1;32m    431\u001b[0m     printd(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot HTTPError, exception=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhttp_err\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, payload=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 432\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m http_err\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mRequestException \u001b[38;5;28;01mas\u001b[39;00m req_err:\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;66;03m# Handle other requests-related errors (e.g., connection error)\u001b[39;00m\n\u001b[1;32m    435\u001b[0m     printd(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot RequestException, exception=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreq_err\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/letta/llm_api/openai.py:422\u001b[0m, in \u001b[0;36mopenai_chat_completions_request\u001b[0;34m(url, api_key, chat_completion_request)\u001b[0m\n\u001b[1;32m    420\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mpost(url, headers\u001b[38;5;241m=\u001b[39mheaders, json\u001b[38;5;241m=\u001b[39mdata)\n\u001b[1;32m    421\u001b[0m printd(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, response.text = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 422\u001b[0m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Raises HTTPError for 4XX/5XX status\u001b[39;00m\n\u001b[1;32m    424\u001b[0m response \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()  \u001b[38;5;66;03m# convert to dict from string\u001b[39;00m\n\u001b[1;32m    425\u001b[0m printd(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse.json = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/requests/models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1019\u001b[0m     http_error_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1020\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Server Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreason\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1021\u001b[0m     )\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
            "\u001b[0;31mHTTPError\u001b[0m: 500 Server Error: Internal Server Error for url: http://jupyter-api-proxy.internal.dlai/rev-proxy/letta/chat/completions"
          ]
        }
      ],
      "source": [
        "response = client.send_message(\n",
        "    agent_id=agent_state.id,\n",
        "    message=\"hello!\",\n",
        "    role=\"user\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75cc6a09-6c24-4b45-8b92-6084acdc3d46",
      "metadata": {
        "height": 30,
        "id": "75cc6a09-6c24-4b45-8b92-6084acdc3d46"
      },
      "outputs": [],
      "source": [
        "response.usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de7b9f35-8599-4465-952a-b2db2d7b1533",
      "metadata": {
        "height": 30,
        "id": "de7b9f35-8599-4465-952a-b2db2d7b1533"
      },
      "outputs": [],
      "source": [
        "nb_print(response.messages)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ebc1999-7099-4d9c-a382-9eb464393cad",
      "metadata": {
        "id": "6ebc1999-7099-4d9c-a382-9eb464393cad"
      },
      "source": [
        "### Understanding agent state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2df27d7b-d2b6-4d87-90c3-6759a70fa8d7",
      "metadata": {
        "height": 30,
        "id": "2df27d7b-d2b6-4d87-90c3-6759a70fa8d7"
      },
      "outputs": [],
      "source": [
        "print(agent_state.system)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "571e53e5-4190-4787-9cb2-efc527885c2d",
      "metadata": {
        "height": 30,
        "id": "571e53e5-4190-4787-9cb2-efc527885c2d"
      },
      "outputs": [],
      "source": [
        "agent_state.tools"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f2c91a5-a5eb-4874-98cf-6f51b70b469e",
      "metadata": {
        "id": "8f2c91a5-a5eb-4874-98cf-6f51b70b469e"
      },
      "source": [
        "### Viewing an agent's memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85ddb91c-5d8c-4f1c-87fd-f8c2b75f7990",
      "metadata": {
        "height": 30,
        "id": "85ddb91c-5d8c-4f1c-87fd-f8c2b75f7990"
      },
      "outputs": [],
      "source": [
        "agent_state.memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7cc0a070-d3e5-4832-90af-99d3544862e2",
      "metadata": {
        "height": 30,
        "id": "7cc0a070-d3e5-4832-90af-99d3544862e2"
      },
      "outputs": [],
      "source": [
        "client.get_archival_memory_summary(agent_state.id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "356e2cb1-a89a-4e56-8bed-1aabfd92bb09",
      "metadata": {
        "height": 30,
        "id": "356e2cb1-a89a-4e56-8bed-1aabfd92bb09"
      },
      "outputs": [],
      "source": [
        "client.get_recall_memory_summary(agent_state.id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6e64ee5-fc01-436c-839a-73e65fb162c9",
      "metadata": {
        "height": 30,
        "id": "a6e64ee5-fc01-436c-839a-73e65fb162c9"
      },
      "outputs": [],
      "source": [
        "client.get_messages(agent_state.id)[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f40da4d-ef39-4f09-ad8a-f8c5b7ef218e",
      "metadata": {
        "id": "1f40da4d-ef39-4f09-ad8a-f8c5b7ef218e"
      },
      "source": [
        "## Section 2: Understanding core memory"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e853571c-cc6b-4f28-b808-aab90031c0a3",
      "metadata": {
        "id": "e853571c-cc6b-4f28-b808-aab90031c0a3"
      },
      "source": [
        "### Memories about the human"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "228ba181-b0bf-4f04-bf94-1e520caeafc3",
      "metadata": {
        "height": 115,
        "id": "228ba181-b0bf-4f04-bf94-1e520caeafc3"
      },
      "outputs": [],
      "source": [
        "response = client.send_message(\n",
        "    agent_id=agent_state.id,\n",
        "    message = \"My name is actually Bob\",\n",
        "    role = \"user\"\n",
        ")\n",
        "nb_print(response.messages)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77b645cc-19ed-4d1a-a37b-e8231237867f",
      "metadata": {
        "id": "77b645cc-19ed-4d1a-a37b-e8231237867f"
      },
      "source": [
        "### Memories about the agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdcc39c5-311d-446e-9562-fa88eb2a10d1",
      "metadata": {
        "height": 130,
        "id": "bdcc39c5-311d-446e-9562-fa88eb2a10d1"
      },
      "outputs": [],
      "source": [
        "response = client.send_message(\n",
        "    agent_id=agent_state.id,\n",
        "    message = \"In the future, never use emojis to communicate\",\n",
        "    role = \"user\"\n",
        ")\n",
        "nb_print(response.messages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1d96101-c229-47d4-8179-8389cd10e6e8",
      "metadata": {
        "height": 45,
        "id": "c1d96101-c229-47d4-8179-8389cd10e6e8"
      },
      "outputs": [],
      "source": [
        "client.get_core_memory(agent_state.id).get_block('persona')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90d50b48-2316-4817-b633-48a2cda83dc7",
      "metadata": {
        "id": "90d50b48-2316-4817-b633-48a2cda83dc7"
      },
      "source": [
        "## Section 3: Understanding archival memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e1dd11c-31a6-4d8e-b713-c6bab84ddea1",
      "metadata": {
        "height": 30,
        "id": "4e1dd11c-31a6-4d8e-b713-c6bab84ddea1"
      },
      "outputs": [],
      "source": [
        "client.get_archival_memory(agent_state.id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abce960f-aaad-459c-82fc-c0c0e50543c1",
      "metadata": {
        "height": 130,
        "id": "abce960f-aaad-459c-82fc-c0c0e50543c1"
      },
      "outputs": [],
      "source": [
        "response = client.send_message(\n",
        "    agent_id=agent_state.id,\n",
        "    message = \"Save the information that 'bob loves cats' to archival\",\n",
        "    role = \"user\"\n",
        ")\n",
        "nb_print(response.messages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93f066b8-77dc-4fcf-8c2c-f280338d8e75",
      "metadata": {
        "height": 30,
        "id": "93f066b8-77dc-4fcf-8c2c-f280338d8e75"
      },
      "outputs": [],
      "source": [
        "client.get_archival_memory(agent_state.id)[0].text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58fc8e82-73ab-4c44-be6d-a911dae0acbc",
      "metadata": {
        "height": 81,
        "id": "58fc8e82-73ab-4c44-be6d-a911dae0acbc"
      },
      "outputs": [],
      "source": [
        "passage = client.insert_archival_memory(\n",
        "    agent_state.id,\n",
        "    \"Bob loves Boston Terriers\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06c5de70-8db8-468a-aa50-018fa2f80ed6",
      "metadata": {
        "height": 30,
        "id": "06c5de70-8db8-468a-aa50-018fa2f80ed6"
      },
      "outputs": [],
      "source": [
        "passage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "673cabb2-83bb-4e7d-baed-eed6c6c67e7a",
      "metadata": {
        "height": 130,
        "id": "673cabb2-83bb-4e7d-baed-eed6c6c67e7a"
      },
      "outputs": [],
      "source": [
        "response = client.send_message(\n",
        "    agent_id=agent_state.id,\n",
        "    role=\"user\",\n",
        "    message=\"What animals do I like? Search archival.\"\n",
        ")\n",
        "nb_print(response.messages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9d7ebbe-12f3-4949-bc89-0dc1e3b85c42",
      "metadata": {
        "height": 30,
        "id": "e9d7ebbe-12f3-4949-bc89-0dc1e3b85c42"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d452213f-b977-4a88-ba56-726216a9d218",
      "metadata": {
        "height": 30,
        "id": "d452213f-b977-4a88-ba56-726216a9d218"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}